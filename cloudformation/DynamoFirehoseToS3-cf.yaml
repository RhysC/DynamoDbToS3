AWSTemplateFormatVersion: '2010-09-09'

Parameters:
  TableName:
      Description: "The name of the DynamoDb table that the data pipeline will be created for"
      Type: String
      Default: rhystest-table

Resources:

  LambdaToFirehoseRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Sub "${TableName}-lambda-to-firehose-role"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "lambda.amazonaws.com"
            Action: "sts:AssumeRole"
      Policies:
        -
          PolicyName: !Sub "${TableName}-lambda-to-firehose-policy"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "dynamodb:GetRecords"
                  - "dynamodb:GetShardIterator"
                  - "dynamodb:DescribeStream"
                  - "dynamodb:ListStreams"
                Resource:
                  Fn::ImportValue:
                    !Sub "${TableName}-dynamodb-stream-arn"
              -
                Effect: "Allow"
                Action:
                  - "firehose:PutRecord"
                  - "firehose:PutRecordBatch"
                Resource: !Sub "arn:aws:firehose:${AWS::Region}:${AWS::AccountId}:deliverystream/${DataFirehoseStream}"
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: "*"
              -
                Effect: "Allow"
                Action:
                  - "xray:PutTraceSegments"
                  - "xray:PutTelemetryRecords"
                Resource: "*"

  DynamoEventsToFirehoseLambda:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: !Sub "${TableName}-lambda-to-firehose-function"
      Handler: "index.handler"
      Role: !GetAtt LambdaToFirehoseRole.Arn
      Code:
        ZipFile:
          Fn::Join:
            - "\n"
            - - ""
              - "'use strict';"
              - "var AWS = require('aws-sdk');"
              - ""
              - "console.log('Loading function');"
              - ""
              - "var firehose = new AWS.Firehose({"
              - "    apiVersion: '2015-08-04',"
              - "});"
              - ""
              - "exports.handler = (event, context, callback) => {"
              - "    let json_records = event.Records.map(function(rec) { return JSON.stringify(rec['dynamodb']).replace(/(?:\\r\\n|\\r|\\n)/g, '\\\\n') + '\\n'; });"
              - "    let mapped_records = json_records.map(function(rec){ return {'Data': rec }; });"
              - "    console.log('Records to be sent: ' + json_records.join(''));"
              - ""
              - "    let params = {"
              - !Sub "      DeliveryStreamName: '${TableName}-firehose',"
              - "      Records: mapped_records"
              - "    };"
              - "    firehose.putRecordBatch(params, function(err, data) {"
              - "      if (err) {"
              - "        console.log(err, err.stack); // an error occurred"
              - "      }"
              - "      else{"
              - "        console.log(data);           // successful response"
              - "      }"
              - "    });"
              - "    callback(null, 'Successfully processed ${event.Records.length} records.');"
              - "};"
      Runtime: "nodejs4.3"
      Timeout: "25"

  DynamoEventsToFirehoseLambdaEventSourceMapping:
    Type: "AWS::Lambda::EventSourceMapping"
    Properties:
      Enabled: true
      EventSourceArn:
        Fn::ImportValue:
          !Sub "${TableName}-dynamodb-stream-arn"
      FunctionName: !GetAtt DynamoEventsToFirehoseLambda.Arn
      StartingPosition: "TRIM_HORIZON"

  S3EventsBucketName:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub "${TableName}-firehose-bucket"
      VersioningConfiguration:
        Status: Suspended

  DataFirehoseToS3Role:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Sub "${TableName}-firehose-to-s3-role"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "firehose.amazonaws.com"
            Action: "sts:AssumeRole"
            Condition:
              StringEquals:
                "sts:ExternalId":
                  Ref: "AWS::AccountId"
      Policies:
        -
          PolicyName: !Sub "${TableName}-firehose-to-s3-policy"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "s3:PutObject"
                  - "s3:AbortMultipartUpload"
                  - "s3:GetBucketLocation"
                  - "s3:GetObject"
                  - "s3:ListBucket"
                  - "s3:ListBucketMultipartUploads"
                Resource:
                  - !Sub "arn:aws:s3:::${S3EventsBucketName}"
                  - !Sub "arn:aws:s3:::${S3EventsBucketName}/*"
              # -
              #   Effect: "Allow"
              #   Action:
              #     - "kms:Decrypt",
              #     - "kms:GenerateDataKey"
              #   Resource:
              #     - Fn::Join:
              #       - ""
              #       - - "arn:aws:kms:"
              #         - Ref: "AWS::Region"
              #         - ":"
              #         - Ref: "AWS::AccountId"
              #         - ":key/"
              #         - Ref: AwsKeyId
              #   Condition:
              #     StringEquals:
              #       "kms:ViaService":
              #         Fn::Join:
              #           - ""
              #           - - "s3."
              #             - Ref: "AWS::Region"
              #             - ".amazonaws.com"
              #     StringEquals:
              #       "kms:EncryptionContext:aws:s3:arn":
              #         Fn::Join:
              #           - ""
              #           - - "arn:aws:s3:::"
              #             - !Ref S3EventsBucketName
              #             - "/*"
              #
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: "*"

  DataFirehoseStream:
    Type: "AWS::KinesisFirehose::DeliveryStream"
    Properties:
      DeliveryStreamName: !Sub "${TableName}-firehose"
      S3DestinationConfiguration:
        BucketARN: !Sub "arn:aws:s3:::${S3EventsBucketName}"
        BufferingHints:
          IntervalInSeconds: 60
          SizeInMBs: 2
        CompressionFormat: UNCOMPRESSED #GZIP
        Prefix: "" # I dont think we should default a prefix, unless we decide to share buckets
        RoleARN: !GetAtt DataFirehoseToS3Role.Arn
        #EncryptionConfiguration:  EncryptionConfiguration - we can do this when we can manage keys
